{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generierung von Dummy Daten \n",
    "- kein Personenbezug\n",
    "- Format und Struktur des Datensatzes bleibt erhalten\n",
    "- Ziel Datensatz teilen zur Verprobung von Forschungsidee, Software etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer zu Datenformat mit einbauen:\n",
    "Note that apart from Microsoft Excel files, only two dimensional data is currently supported for automatic upload and each column has to be a separate variable (as opposed to variables being contained in rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(x):\n",
    "    if (x.endswith(('csv', 'txt'))):\n",
    "        return pd.read_csv(x) \n",
    "    elif (x.endswith(('xlsx', 'xls'))):\n",
    "        dictionary = pd.read_excel(x, sheet_name = None) \n",
    "        if (len(dictionary.keys()) == 1):\n",
    "            name_of_sheet = list(dictionary.keys())\n",
    "            name_of_sheet = name_of_sheet[0]\n",
    "            simple_data_frame = dictionary[name_of_sheet]\n",
    "            return simple_data_frame\n",
    "        else:\n",
    "            return dictionary\n",
    "    elif (x.endswith('sas7bdat')):\n",
    "        return pd.read_sas(x) \n",
    "    elif (x.endswith('sav')):\n",
    "        return pd.read_spss(x) \n",
    "    elif (x.endswith('dta')):\n",
    "        return pd.read_stata(x)  \n",
    "    elif (x.endswith('pkl')):\n",
    "        return pd.read_pickle(x) \n",
    "    else:\n",
    "        raise Exception(\"Sorry, file type not supported. Try converting to csv, xlsx, txt or pkl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write test for function to see that sas and stata files run properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datetime, numeric, categorical, only na, string, \n",
    "\n",
    "# pattern abbilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                 int64\n",
       "Age                              float64\n",
       "BMI                              float64\n",
       "Sex                               object\n",
       "Height                           float64\n",
       "Weight                           float64\n",
       "Length_of_Stay                   float64\n",
       "Management                        object\n",
       "Severity                          object\n",
       "Alvarado_Score                   float64\n",
       "Paedriatic_Appendicitis_Score    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './data/RPAD_data_small.xlsx'\n",
    "original_data = read_data(file_path)\n",
    "original_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                        Int64\n",
       "Age                                     Float64\n",
       "BMI                                     Float64\n",
       "Sex                              string[python]\n",
       "Height                                  Float64\n",
       "Weight                                  Float64\n",
       "Length_of_Stay                            Int64\n",
       "Management                       string[python]\n",
       "Severity                         string[python]\n",
       "Alvarado_Score                            Int64\n",
       "Paedriatic_Appendicitis_Score             Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = original_data.convert_dtypes()\n",
    "dfn.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel sheet check mit einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kategorische variablen sollten per hand definiert werden mit wissen welcher datentyp da ist\n",
    "- anzahl unterschiedlicher werte (wenige = kategorische Variable)\n",
    "- Anzahl unterschiedlicher Werte in % von Anzahl Werte insgesamt als Indikator nutzen:\n",
    "bspw. Anzahl unterschiedlicher Werte kleiner als 5% im Datensatz Variable wird Kategorisch geschätzt: Datensatz kleiner als 20 Beobachtungen wird keine Kategorie erkannt -> Anpassen der % Schwelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                  Int64\n",
       "Age                               Float64\n",
       "BMI                               Float64\n",
       "Sex                              category\n",
       "Height                            Float64\n",
       "Weight                            Float64\n",
       "Length_of_Stay                   category\n",
       "Management                       category\n",
       "Severity                         category\n",
       "Alvarado_Score                   category\n",
       "Paedriatic_Appendicitis_Score    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#category \n",
    "for name, column in dfn.items():\n",
    "    unique_count = column.unique().shape[0]\n",
    "    total_count = column.shape[0]\n",
    "    if unique_count / total_count < 0.1:\n",
    "        dfn[name] = dfn[name].astype('category')\n",
    "\n",
    "dfn.dtypes\n",
    "\n",
    "# Problem kategorische Variable lenght_of_stay -> 20 unique values bei 780 Beobachtungen\n",
    "# -> Threshold müsste bei 0.02 liegen -> in diesem Fall fine evt gestaffelt (ab 100 andere Zahl udn ab 50, 20 und 10?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we generate synthetic data. This data set will have the same column names, structure and number of rows as your original data set. Freuency of NAs values will be preserved (albeit with the introduction of some noise). Values found in columns will be largely similar (e.g. similar structure of string values, similar frequency of categories for categorical values etc). The new data set will have 'synthetic' appended to its file name and saved as a .csv file in your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>8578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>7848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>8845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>5431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID\n",
       "0    7898\n",
       "1    6952\n",
       "2    7909\n",
       "3    8163\n",
       "4    1933\n",
       "..    ...\n",
       "777  8578\n",
       "778  2087\n",
       "779  7848\n",
       "780  8845\n",
       "781  5431\n",
       "\n",
       "[782 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.select_dtypes(include=\"Int64\")\n",
    "new_col = pd.Series(new_col).replace('nan', np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create synth data:\n",
    "1. check number of nan rows -> generate random number of nan rows (between 0.7 and 1.3 threshold of number nan in real data)\n",
    "2. nan columns remain nan columns\n",
    "3. create categorical columns\n",
    "4. create numeric columns\n",
    "5. create datetime\n",
    "6. string vars -> similar length -> pattern detected -> recreate pattern? -> recreate names, adress lines etc with faker? -> detect adresslines?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoveredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
